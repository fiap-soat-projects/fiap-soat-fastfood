# üçî FastFood API

Este projeto foi desenvolvido para o curso de [p√≥s-gradua√ß√£o em Arquitetura de Software (Soat P√≥stech) da FIAP](https://postech.fiap.com.br/curso/software-architecture/).

A API presente neste reposit√≥rio disponibiliza rotas para gerenciamento de clientes, card√°pio, pedidos e pagamentos, com integra√ß√£o direta com [MongoDB](https://www.mongodb.com/) e [Mercado Pago](https://www.mercadopago.com.br/developers/pt/reference).

## üèÉ Integrantes do grupo 21

- Jeferson dos Santos Gomes - **RM 362669**
- Jamison dos Santos Gomes - **RM 362671**
- Alison da Silva Cruz - **RM 362628**

## üìú Linguagem Ub√≠qua 

Para mais detalhes sobre a linguagem do dom√≠nio, consulte [`docs/ubiquitous-language.md`](docs/ubiquitous-language.md).

## üóÇÔ∏è Diagramas do Projeto

Os seguintes diagramas est√£o dispon√≠veis no diret√≥rio [`/diagrams`](diagrams):

- **Diagrama de Contexto:** Apresenta uma vis√£o geral dos sistemas e atores que interagem com a FastFood API, destacando integra√ß√µes externas e fluxos principais.

- **Event Storming:** Ilustra os principais eventos de neg√≥cio, comandos e agregados do dom√≠nio, facilitando o entendimento dos fluxos e regras do sistema.

- **Domain Storytelling:** Mostra narrativas visuais dos processos de neg√≥cio, detalhando como os diferentes atores interagem com o sistema em cen√°rios t√≠picos.

Consulte o diret√≥rio [`/diagrams`](diagrams) para visualizar os arquivos e obter mais detalhes sobre cada diagrama.

## üë®‚Äçüíª Tecnologias Utilizadas

- **.NET 8** (C# 12)
- **ASP.NET Core Web API**
- **MongoDB** (banco de dados)
- **Mongo Express** (cliente web para MongoDB)
- **Docker** e **Docker Compose**
- **Kubernetes** (gerenciamento de containers)
- **Keda** (escalonamento)
- **Prometheus** (m√©tricas)
- **Polly** (resili√™ncia HTTP)
- **Swagger** (documenta√ß√£o autom√°tica)
- **MercadoPago** (integra√ß√£o de pagamentos via Pix)

## üèÅ Como Inicializar

### Pr√©-requisitos

- üêà‚Äç‚¨õ Clonar este [Reposit√≥rio](https://github.com/jefersondsgomes/fiap-soat-fastfood)
- üê≥ Instalar o [Docker](https://www.docker.com/get-started/)
- ‚ò∏Ô∏è Habilitar o Kubernetes no [Docker](https://docs.docker.com/desktop/features/kubernetes/)

Podemos executar essa aplica√ß√£o de 2 maneiras diferentes:

### 1. **Docker**:

No diret√≥rio raiz do projeto, utilize uma ferramenta de linha de comando de sua prefer√™ncia e execute o comando `docker-compose up --build`.

A API e seus recursos est√£o dispon√≠veis em:
- **API**: [http://localhost:8080/swagger](http://localhost:8080/swagger)
- **Mongo Express**: [http://localhost:8081](http://localhost:8081)

### 2. **Kubernetes**:

No nosso reposit√≥rio temos o diret√≥rio `/k8s` onde disponibilizamos todos os manifestos associados ao deploy e configura√ß√£o da nossa API e banco de dados. Nesse contexto, temos a possibilidade de escalar nossa aplica√ß√£o com base em m√©tricas fornecidas pela API.

Para utilizar esses recursos, precisaremos de alguns passos adicionais para prepara√ß√£o do ambiente:

2.1 **Criar `namespaces` personalizados no Kubernetes**:

   Com o cluster **K8s** habilitado, precisaremos executar os seguintes comandos:

   - `kubectl create namespace fiap`
   - `kubectl create namespace keda`
   - `kubectl create namespace monitoring`

2.2 **‚öì [Instalar o Helm](https://helm.sh/docs/intro/install/)**

   O Helm √© um gerenciador de pacotes para o Kubernetes e, atrav√©s dele, podemos provisionar aplica√ß√µes e ambientes inteiros de maneira simplificada. 

   Para facilitar as coisas, essa instala√ß√£o tamb√©m pode ser feita a partir do comando abaixo:

   - `curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash`

2.3 **Configurar servi√ßos adicionais no K8s**:

   Temos 2 servi√ßos principais que precisam estar em execu√ß√£o no nosso cluster **K8s** para que seja poss√≠vel coletar as m√©tricas da nossa aplica√ß√£o e ajustar a escala dinamicamente. Para instalar esses recursos, precisamos que o **Helm** (passo 2) esteja dispon√≠vel.

   ##### - **Instala√ß√£o do [KEDA](https://keda.sh/docs/2.9/deploy/)**

   O **KEDA** √© um componente para o **K8s** que estende as capacidades do HPA. Ele permite que as aplica√ß√µes escalem automaticamente com base em m√©tricas de eventos externas, indo muito al√©m das m√©tricas de CPU e mem√≥ria padr√£o.

   Utilizando o **Helm**, execute os comandos abaixo:
   
   - `helm repo add kedacore https://kedacore.github.io/charts`
   - `helm repo update`
   - `helm install keda kedacore/keda -n keda`

   ##### - **Instala√ß√£o do [Prometheus](https://grafana.com/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/configuration/config-other-methods/prometheus/prometheus-operator/)**

   O **Prometheus** √© uma ferramenta de monitoramento e alertas voltada para m√©tricas de sistemas. Ele coleta dados em tempo real por meio de pulls em endpoints HTTP. As m√©tricas s√£o armazenadas em uma base de dados temporal e podem ser consultadas com a linguagem PromQL.

   Execute os comandos abaixo:

   - `helm repo add prometheus-community https://prometheus-community.github.io/helm-charts`
   - `helm repo update`
   - `helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring`
   - `helm install prometheus-adapter prometheus-community/prometheus-adapter -n monitoring`
   
   ##### - Instala√ß√£o do [Metrics Server](https://github.com/kubernetes-sigs/metrics-server)

   O **Metrics Server** √© um agregador de m√©tricas de recursos usado pelo Kubernetes para fornecer dados de uso de CPU e mem√≥ria dos pods e nodes. Ele √© essencial para o funcionamento do HPA (Horizontal Pod Autoscaler) e para que ferramentas como o KEDA possam escalar os pods com base nessas m√©tricas.

   Para instalar o Metrics Server, execute os comandos abaixo:

   ```sh
   kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
   ```

   Se estiver rodando o cluster localmente (ex: Docker Desktop), pode ser necess√°rio ajustar o deployment para permitir conex√µes inseguras (por exemplo, adicionar o argumento `--kubelet-insecure-tls`):

   ```sh
   kubectl -n kube-system edit deployment metrics-server
   ```
   Adicione o argumento abaixo em `spec.containers.args`:
   ```yaml
   - --kubelet-insecure-tls
   ```

   Ap√≥s a instala√ß√£o, verifique se o Metrics Server est√° funcionando corretamente:

   ```sh
   kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes"
   ```

   Se retornar dados dos nodes, est√° tudo certo!

2.4 Aplicar manifestos

Acesse o diret√≥rio `/k8s` e execute o comando `kubectl apply -f .`, isso far√° com que todos os recursos descritos nos manifestos sejam aplicados no **K8s**. Com essa a√ß√£o, teremos as APIs dispon√≠veis em `http://localhost:30080`.

---

### Arquitetura K8s:

![soat-fastfood-architecture.drawio.png](./diagrams/img/soat-fastfood-architecture.drawio.png)

## Dicas e Truques:

- Utilize o Kubernetes com **[K9S](https://k9scli.io/)**: O **K9S** √© uma interface para terminal que permite uma navega√ß√£o simplificada entre os recursos do Kubernetes. √â uma excelente ferramenta de produtividade, pois elimina as diversas chamadas que normalmente s√£o realizadas atrav√©s do `kubectl`.

- Utilize o **[K6](https://k6.io/)** para testar o scaling: O **K6** √© uma ferramenta para execu√ß√£o de testes de carga. Neste projeto, temos o diret√≥rio `/k6` onde disponibilizamos scripts que ir√£o estressar alguns endpoints do nosso servi√ßo e, caso esteja executando no **K8s**, ser√° poss√≠vel verificar o scaling up e scaling down.

- Visualize as informa√ß√µes no **Prometheus**: No **K8s** temos uma stack do Prometheus em execu√ß√£o e √© poss√≠vel fazer um port-forward para que a UI seja acess√≠vel externamente. Para isso, execute o comando `kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090` e acesse em `http://localhost:9090`.

## Endpoints Dispon√≠veis

### üçî Order (Pedido)
- `GET /order?page=1&size=10&status=Received` ‚Äî Listar todos pedidos em p√°gina
- `GET /order/active?page=1&size=10` ‚Äî Listar pedidos ativos em p√°gina de forma ordenada e excluindo pedidos inativos.
- `GET /order/{id}` ‚Äî Detalhar pedido
- `POST /order` ‚Äî Criar pedido
- `PATCH /order/{id}/status` ‚Äî Atualizar status do pedido
- `DELETE /order/{id}` ‚Äî Remover pedido

### üí∏ Transaction (Pagamento)
- `POST /order/{id}/checkout` ‚Äî Iniciar checkout/pagamento
- `POST /order/{id}/confirm-payment` ‚Äî Confirmar pagamento
- `POST /order/payment/webhook` ‚Äî Webhook de pagamento

### ü§ñ SelfOrdering (Cliente)
- `GET /self-ordering/customer/{id}` ‚Äî Buscar cliente por ID
- `GET /self-ordering/customer/{cpf}` ‚Äî Buscar cliente por CPF
- `POST /self-ordering/customer` ‚Äî Registrar cliente

### üì≤ Menu (Card√°pio)
- `GET /menu/{id}` ‚Äî Detalhar item do card√°pio
- `GET /menu?name=string&category=0&skip=0&limit=10` ‚Äî Listar itens do card√°pio
- `POST /menu` ‚Äî Cadastrar item no card√°pio
- `PUT /menu/{id}` ‚Äî Atualizar item do card√°pio
- `DELETE /menu/{id}` ‚Äî Remover item do card√°pio

### üè• HealthCheck (Sa√∫de)
- `GET /healthz` ‚Äî Sa√∫de da API
- `GET /health` ‚Äî Sa√∫de da API e suas depend√™ncias

### üìà Metrics (M√©tricas)
- `GET /metrics` ‚Äî M√©tricas do Prometheus

Se preferir, as requisi√ß√µes descritas acima podem ser acessadas via [Postman](https://www.postman.com/) por meio da seguinte documenta√ß√£o:

- [fiap-soat-fastfood](https://documenter.getpostman.com/view/7741479/2sB3BAMYQs)

## üë§ Conven√ß√µes

- Todos os endpoints aceitam e retornam JSON.
- Utilize o Swagger para explorar e testar os endpoints.

## üè¶ Banco de Dados

- O MongoDB inicializa com uma seed de dados para um card√°pio pr√©-preenchido. Isso ocorre via script em `scripts/init-db.js`.
- Por padr√£o o script n√£o esta com os valores de usu√°rio e senha configurados √© necess√°rio realizar a configura√ß√£o manualmente, √© possivel encontrar atrav√©s dos placeholders: {{username}} e {{password}}.

---

## üß© Arquitetura: Princ√≠pios SOLID & Clean Architecture

Este projeto foi estruturado seguindo os princ√≠pios do **SOLID** e os conceitos do **Clean Architecture**, visando garantir um sistema desacoplado, coeso, test√°vel e de f√°cil manuten√ß√£o.

### Princ√≠pios SOLID

- **S**ingle Responsibility Principle (Responsabilidade √önica):  
  Cada classe ou m√≥dulo possui uma √∫nica responsabilidade bem definida, facilitando a manuten√ß√£o e evolu√ß√£o do c√≥digo.

- **O**pen/Closed Principle (Aberto/Fechado):  
  Os componentes do sistema s√£o abertos para extens√£o, mas fechados para modifica√ß√£o, permitindo adicionar novas funcionalidades sem alterar o c√≥digo existente.

- **L**iskov Substitution Principle (Substitui√ß√£o de Liskov):  
  As subclasses podem ser substitu√≠das por suas classes base sem afetar o funcionamento do sistema.

- **I**nterface Segregation Principle (Segrega√ß√£o de Interfaces):  
  Interfaces espec√≠ficas s√£o preferidas a interfaces gen√©ricas, evitando que classes dependam de m√©todos que n√£o utilizam.

- **D**ependency Inversion Principle (Invers√£o de Depend√™ncia):  
  O dom√≠nio depende de abstra√ß√µes (interfaces), e n√£o de implementa√ß√µes concretas, promovendo baixo acoplamento entre as camadas.

### Clean Architecture

- **Separa√ß√£o de Camadas:**  
  O projeto √© dividido em camadas bem definidas, separada por projetos de Business, Adapters, Drivers(Api, Infrastructure)

- **Isolamento da L√≥gica de Neg√≥cio:**  
  A l√≥gica de neg√≥cio reside na camada de dom√≠nio (Business), isolada de detalhes t√©cnicos e de infraestrutura.

- **Gateways e Interfaces:**  
  Depend√™ncias externas (bancos de dados, APIs, etc.) s√£o representadas por interfaces na camada de dom√≠nio. As implementa√ß√µes concretas ficam na infraestrutura.

- **Inje√ß√£o de Depend√™ncias:**  
  A liga√ß√£o entre interfaces e implementa√ß√µes √© feita via inje√ß√£o de depend√™ncias, facilitando testes e substitui√ß√£o de componentes.

**Benef√≠cios:**
- Facilita testes unit√°rios e integra√ß√£o.
- Permite evolu√ß√£o e manuten√ß√£o do sistema sem impactar a l√≥gica de neg√≥cio.
- Garante flexibilidade para trocar tecnologias e integra√ß√µes externas.
- Segue as melhores pr√°ticas de arquitetura de software moderna.

> **Resumo:**  
> O projeto foi desenhado para que cada camada tenha responsabilidades claras e isoladas, promovendo um c√≥digo limpo, sustent√°vel e preparado para mudan√ßas futuras.
