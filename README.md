# ğŸ” FastFood API

Este projeto foi desenvolvido para o curso de [pÃ³s-graduaÃ§Ã£o em Arquitetura de Software (Soat PÃ³stech) da FIAP](https://postech.fiap.com.br/curso/software-architecture/).

A API presente neste repositÃ³rio disponibiliza rotas para gerenciamento de clientes, cardÃ¡pio, pedidos e pagamentos, com integraÃ§Ã£o direta com [MongoDB](https://www.mongodb.com/) e [Mercado Pago](https://www.mercadopago.com.br/developers/pt/reference).

## ğŸƒ Integrantes do grupo 21

- Jeferson dos Santos Gomes - **RM 362669**
- Jamison dos Santos Gomes - **RM 362671**
- Alison da Silva Cruz - **RM 362628**

## ğŸ“œ Linguagem UbÃ­qua 

Para mais detalhes sobre a linguagem do domÃ­nio, consulte [`docs/ubiquitous-language.md`](docs/ubiquitous-language.md).

## ğŸ—‚ï¸ Diagramas do Projeto

Os seguintes diagramas estÃ£o disponÃ­veis no diretÃ³rio [`/diagrams`](diagrams):

- **Diagrama de Contexto:** Apresenta uma visÃ£o geral dos sistemas e atores que interagem com a FastFood API, destacando integraÃ§Ãµes externas e fluxos principais.

- **Event Storming:** Ilustra os principais eventos de negÃ³cio, comandos e agregados do domÃ­nio, facilitando o entendimento dos fluxos e regras do sistema.

- **Domain Storytelling:** Mostra narrativas visuais dos processos de negÃ³cio, detalhando como os diferentes atores interagem com o sistema em cenÃ¡rios tÃ­picos.

Consulte o diretÃ³rio [`/diagrams`](diagrams) para visualizar os arquivos e obter mais detalhes sobre cada diagrama.

## ğŸ‘¨â€ğŸ’» Tecnologias Utilizadas

- **.NET 8** (C# 12)
- **ASP.NET Core Web API**
- **MongoDB** (banco de dados)
- **Mongo Express** (cliente web para MongoDB)
- **Docker** e **Docker Compose**
- **Kubernetes** (gerenciamento de containers)
- **Keda** (escalonamento)
- **Prometheus** (mÃ©tricas)
- **Polly** (resiliÃªncia HTTP)
- **Swagger** (documentaÃ§Ã£o automÃ¡tica)
- **MercadoPago** (integraÃ§Ã£o de pagamentos via Pix)

## ğŸ Como Inicializar

### PrÃ©-requisitos

- ğŸˆâ€â¬› Clonar este [RepositÃ³rio](https://github.com/jefersondsgomes/fiap-soat-fastfood)
- ğŸ³ Instalar o [Docker](https://www.docker.com/get-started/)
- â˜¸ï¸ Habilitar o Kubernetes no [Docker](https://docs.docker.com/desktop/features/kubernetes/)

Podemos executar essa aplicaÃ§Ã£o de 2 maneiras diferentes:

### 1. **Docker**:

No diretÃ³rio raiz do projeto, utilize uma ferramenta de linha de comando de sua preferÃªncia e execute o comando `docker-compose up --build`.

A API e seus recursos estÃ£o disponÃ­veis em:
- **API**: [http://localhost:8080/swagger](http://localhost:8080/swagger)
- **Mongo Express**: [http://localhost:8081](http://localhost:8081)

### 2. **Kubernetes**:

No nosso repositÃ³rio temos o diretÃ³rio `/k8s` onde disponibilizamos todos os manifestos associados ao deploy e configuraÃ§Ã£o da nossa API e banco de dados. Nesse contexto, temos a possibilidade de escalar nossa aplicaÃ§Ã£o com base em mÃ©tricas fornecidas pela API.

Para utilizar esses recursos, precisaremos de alguns passos adicionais para preparaÃ§Ã£o do ambiente:

2.1 **Criar `namespaces` personalizados no Kubernetes**:

   Com o cluster **K8s** habilitado, precisaremos executar os seguintes comandos:

   - `kubectl create namespace fiap`
   - `kubectl create namespace keda`
   - `kubectl create namespace monitoring`

2.2 **âš“ [Instalar o Helm](https://helm.sh/docs/intro/install/)**

   O Helm Ã© um gerenciador de pacotes para o Kubernetes e, atravÃ©s dele, podemos provisionar aplicaÃ§Ãµes e ambientes inteiros de maneira simplificada. 

   Para facilitar as coisas, essa instalaÃ§Ã£o tambÃ©m pode ser feita a partir do comando abaixo:

   - `curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash`

2.3 **Configurar serviÃ§os adicionais no K8s**:

   Temos 2 serviÃ§os principais que precisam estar em execuÃ§Ã£o no nosso cluster **K8s** para que seja possÃ­vel coletar as mÃ©tricas da nossa aplicaÃ§Ã£o e ajustar a escala dinamicamente. Para instalar esses recursos, precisamos que o **Helm** (passo 2) esteja disponÃ­vel.

   ##### - **InstalaÃ§Ã£o do [KEDA](https://keda.sh/docs/2.9/deploy/)**

   O **KEDA** Ã© um componente para o **K8s** que estende as capacidades do HPA. Ele permite que as aplicaÃ§Ãµes escalem automaticamente com base em mÃ©tricas de eventos externas, indo muito alÃ©m das mÃ©tricas de CPU e memÃ³ria padrÃ£o.

   Utilizando o **Helm**, execute os comandos abaixo:
   
   - `helm repo add kedacore https://kedacore.github.io/charts`
   - `helm repo update`
   - `helm install keda kedacore/keda -n keda`

   ##### - **InstalaÃ§Ã£o do [Prometheus](https://grafana.com/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/configuration/config-other-methods/prometheus/prometheus-operator/)**

   O **Prometheus** Ã© uma ferramenta de monitoramento e alertas voltada para mÃ©tricas de sistemas. Ele coleta dados em tempo real por meio de pulls em endpoints HTTP. As mÃ©tricas sÃ£o armazenadas em uma base de dados temporal e podem ser consultadas com a linguagem PromQL.

   Execute os comandos abaixo:

   - `helm repo add prometheus-community https://prometheus-community.github.io/helm-charts`
   - `helm repo update`
   - `helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring`
   - `helm install prometheus-adapter prometheus-community/prometheus-adapter -n monitoring`
   
   ##### - InstalaÃ§Ã£o do [Metrics Server](https://github.com/kubernetes-sigs/metrics-server)

   O **Metrics Server** Ã© um agregador de mÃ©tricas de recursos usado pelo Kubernetes para fornecer dados de uso de CPU e memÃ³ria dos pods e nodes. Ele Ã© essencial para o funcionamento do HPA (Horizontal Pod Autoscaler) e para que ferramentas como o KEDA possam escalar os pods com base nessas mÃ©tricas.

   Para instalar o Metrics Server, execute os comandos abaixo:

   ```sh
   kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
   ```

   Se estiver rodando o cluster localmente (ex: Docker Desktop), pode ser necessÃ¡rio ajustar o deployment para permitir conexÃµes inseguras (por exemplo, adicionar o argumento `--kubelet-insecure-tls`):

   ```sh
   kubectl -n kube-system edit deployment metrics-server
   ```
   Adicione o argumento abaixo em `spec.containers.args`:
   ```yaml
   - --kubelet-insecure-tls
   ```

   ApÃ³s a instalaÃ§Ã£o, verifique se o Metrics Server estÃ¡ funcionando corretamente:

   ```sh
   kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes"
   ```

   Se retornar dados dos nodes, estÃ¡ tudo certo!

2.4 Aplicar manifestos

Acesse o diretÃ³rio `/k8s` e execute o comando `kubectl apply -f .`, isso farÃ¡ com que todos os recursos descritos nos manifestos sejam aplicados no **K8s**. Com essa aÃ§Ã£o, teremos as APIs disponÃ­veis em `http://localhost:30080`.

---

### Arquitetura K8s:

![soat-fastfood-architecture.drawio.png](./diagrams/img/soat-fastfood-architecture.drawio.png)

## Dicas e Truques:

- Utilize o Kubernetes com **[K9S](https://k9scli.io/)**: O **K9S** Ã© uma interface para terminal que permite uma navegaÃ§Ã£o simplificada entre os recursos do Kubernetes. Ã‰ uma excelente ferramenta de produtividade, pois elimina as diversas chamadas que normalmente sÃ£o realizadas atravÃ©s do `kubectl`.

- Utilize o **[K6](https://k6.io/)** para testar o scaling: O **K6** Ã© uma ferramenta para execuÃ§Ã£o de testes de carga. Neste projeto, temos o diretÃ³rio `/k6` onde disponibilizamos scripts que irÃ£o estressar alguns endpoints do nosso serviÃ§o e, caso esteja executando no **K8s**, serÃ¡ possÃ­vel verificar o scaling up e scaling down.

- Visualize as informaÃ§Ãµes no **Prometheus**: No **K8s** temos uma stack do Prometheus em execuÃ§Ã£o e Ã© possÃ­vel fazer um port-forward para que a UI seja acessÃ­vel externamente. Para isso, execute o comando `kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090` e acesse em `http://localhost:9090`.

## Endpoints DisponÃ­veis

### ğŸ” Order (Pedido)
- `GET /order?page=1&size=10&status=Received` â€” Listar todos pedidos em pÃ¡gina
- `GET /order/active?page=1&size=10` â€” Listar pedidos ativos em pÃ¡gina de forma ordenada e excluindo pedidos inativos.
- `GET /order/{id}` â€” Detalhar pedido
- `POST /order` â€” Criar pedido
- `PATCH /order/{id}/status` â€” Atualizar status do pedido
- `DELETE /order/{id}` â€” Remover pedido

### ğŸ’¸ Transaction (Pagamento)
- `POST /order/{id}/checkout` â€” Iniciar checkout/pagamento
- `POST /order/{id}/confirm-payment` â€” Confirmar pagamento
- `POST /order/payment/webhook` â€” Webhook de pagamento

### ğŸ¤– SelfOrdering (Cliente)
- `GET /self-ordering/customer/{id}` â€” Buscar cliente por ID
- `GET /self-ordering/customer/{cpf}` â€” Buscar cliente por CPF
- `POST /self-ordering/customer` â€” Registrar cliente

### ğŸ“² Menu (CardÃ¡pio)
- `GET /menu/{id}` â€” Detalhar item do cardÃ¡pio
- `GET /menu?name=string&category=0&skip=0&limit=10` â€” Listar itens do cardÃ¡pio
- `POST /menu` â€” Cadastrar item no cardÃ¡pio
- `PUT /menu/{id}` â€” Atualizar item do cardÃ¡pio
- `DELETE /menu/{id}` â€” Remover item do cardÃ¡pio

### ğŸ¥ HealthCheck (SaÃºde)
- `GET /healthz` â€” SaÃºde da API
- `GET /health` â€” SaÃºde da API e suas dependÃªncias

### ğŸ“ˆ Metrics (MÃ©tricas)
- `GET /metrics` â€” MÃ©tricas do Prometheus

Se preferir, as requisiÃ§Ãµes descritas acima podem ser acessadas via [Postman](https://www.postman.com/) por meio da seguinte documentaÃ§Ã£o:

- [fiap-soat-fastfood](https://documenter.getpostman.com/view/7741479/2sB3BAMYQs)

## ğŸ‘¤ ConvenÃ§Ãµes

- Todos os endpoints aceitam e retornam JSON.
- Utilize o Swagger para explorar e testar os endpoints.

## ğŸ¦ Banco de Dados

- O MongoDB inicializa com uma seed de dados para um cardÃ¡pio prÃ©-preenchido. Isso ocorre via script em `scripts/init-db.js`.
- Por padrÃ£o o script nÃ£o esta com os valores de usuÃ¡rio e senha configurados Ã© necessÃ¡rio realizar a configuraÃ§Ã£o manualmente, Ã© possivel encontrar atravÃ©s dos placeholders: {{username}} e {{password}}.

---

## ğŸ§© Arquitetura: PrincÃ­pios SOLID & Clean Architecture

Este projeto foi estruturado seguindo os princÃ­pios do **SOLID** e os conceitos do **Clean Architecture**, visando garantir um sistema desacoplado, coeso, testÃ¡vel e de fÃ¡cil manutenÃ§Ã£o.

### PrincÃ­pios SOLID

- **S**ingle Responsibility Principle (Responsabilidade Ãšnica):  
  Cada classe ou mÃ³dulo possui uma Ãºnica responsabilidade bem definida, facilitando a manutenÃ§Ã£o e evoluÃ§Ã£o do cÃ³digo.

- **O**pen/Closed Principle (Aberto/Fechado):  
  Os componentes do sistema sÃ£o abertos para extensÃ£o, mas fechados para modificaÃ§Ã£o, permitindo adicionar novas funcionalidades sem alterar o cÃ³digo existente.

- **L**iskov Substitution Principle (SubstituiÃ§Ã£o de Liskov):  
  As subclasses podem ser substituÃ­das por suas classes base sem afetar o funcionamento do sistema.

- **I**nterface Segregation Principle (SegregaÃ§Ã£o de Interfaces):  
  Interfaces especÃ­ficas sÃ£o preferidas a interfaces genÃ©ricas, evitando que classes dependam de mÃ©todos que nÃ£o utilizam.

- **D**ependency Inversion Principle (InversÃ£o de DependÃªncia):  
  O domÃ­nio depende de abstraÃ§Ãµes (interfaces), e nÃ£o de implementaÃ§Ãµes concretas, promovendo baixo acoplamento entre as camadas.

### Clean Architecture

- **SeparaÃ§Ã£o de Camadas:**  
  O projeto Ã© dividido em camadas bem definidas, separada por projetos de Business, Adapters, Drivers(Api, Infrastructure)

- **Isolamento da LÃ³gica de NegÃ³cio:**  
  A lÃ³gica de negÃ³cio reside na camada de domÃ­nio (Business), isolada de detalhes tÃ©cnicos e de infraestrutura.

- **Gateways e Interfaces:**  
  DependÃªncias externas (bancos de dados, APIs, etc.) sÃ£o representadas por interfaces na camada de domÃ­nio. As implementaÃ§Ãµes concretas ficam na infraestrutura.

- **InjeÃ§Ã£o de DependÃªncias:**  
  A ligaÃ§Ã£o entre interfaces e implementaÃ§Ãµes Ã© feita via injeÃ§Ã£o de dependÃªncias, facilitando testes e substituiÃ§Ã£o de componentes.

**BenefÃ­cios:**
- Facilita testes unitÃ¡rios e integraÃ§Ã£o.
- Permite evoluÃ§Ã£o e manutenÃ§Ã£o do sistema sem impactar a lÃ³gica de negÃ³cio.
- Garante flexibilidade para trocar tecnologias e integraÃ§Ãµes externas.
- Segue as melhores prÃ¡ticas de arquitetura de software moderna.

> **Resumo:**  
> O projeto foi desenhado para que cada camada tenha responsabilidades claras e isoladas, promovendo um cÃ³digo limpo, sustentÃ¡vel e preparado para mudanÃ§as futuras.
